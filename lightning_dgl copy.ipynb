{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "\n",
    "import os\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.dataloading import GraphDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "class GNNModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(3, 16)\n",
    "        self.conv2 = GraphConv(16, 2)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, g):\n",
    "        h = self.conv1(g, g.ndata[\"attr\"].float())\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, \"h\")\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        dgl.data.GINDataset(\"PROTEINS\", self_loop=True)\n",
    "        \n",
    "    def setup(self,stage = None):\n",
    "        # 准备数据集\n",
    "        dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=True)\n",
    "        num_examples = len(dataset)\n",
    "        num_train = int(num_examples * 0.8)\n",
    "        num_validation = int(num_examples * 0.9)\n",
    "\n",
    "        self.train_sampler = Subset(dataset,torch.arange(num_train))\n",
    "        self.test_sampler = Subset(dataset,torch.arange(num_train, num_validation))\n",
    "        self.validation_sampler = Subset(dataset, torch.arange(num_validation, num_examples))\n",
    "        self.predict_sampler = Subset(dataset, list(range(10)))  #将predict的集合缩减为10个样本\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_loader = GraphDataLoader(self.train_sampler, batch_size=5, drop_last = False)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = GraphDataLoader(self.validation_sampler, batch_size=5)\n",
    "        return val_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return GraphDataLoader(self.test_sampler, batch_size=5)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return GraphDataLoader(self.predict_sampler, batch_size=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        acc = accuracy(logits.softmax(dim=-1), y, task='multiclass', num_classes=2)\n",
    "        pbar = {'train_acc': acc}\n",
    "        return {'loss': loss, 'progress_bar': pbar}\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        results = self.training_step(batch, batch_idx)\n",
    "        results['progress_bar']['test_acc'] = results['progress_bar']['train_acc']\n",
    "        self.log('test_loss', results['loss'], prog_bar=True)\n",
    "        self.log('test_acc', results['progress_bar']['test_acc'])\n",
    "        return results\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        avg_test_loss = self.trainer.callback_metrics['test_loss'].item()\n",
    "        avg_test_acc = self.trainer.callback_metrics['test_acc'].item()\n",
    "        print(\"Test epoch ended.\")\n",
    "        print(f\"Mean test loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Mean test accuracy: {avg_test_acc:.4f}\")\n",
    "\n",
    "        #使用train_step进行验证\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        results = self.training_step(batch, batch_idx)\n",
    "        self.log('val_loss',results['loss'], prog_bar=True)\n",
    "        self.log('val_acc',results['progress_bar']['train_acc'])\n",
    "        return results\n",
    "    \n",
    "    #在每次循环结束后计算其损失以及准确率\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = self.trainer.callback_metrics['val_loss'].item()\n",
    "        avg_val_acc = self.trainer.callback_metrics['val_acc'].item()\n",
    "        print(\"Validation epoch ended.\")\n",
    "        \n",
    "        print(f\"Mean validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        print(f\"Mean validation accuracy: {avg_val_acc:.4f}\")\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        logits = self(x)\n",
    "        preds = logits.softmax(dim=-1)\n",
    "        return preds\n",
    "\n",
    "    def on_predict_batch_end(self, outputs, batch, batch_idx):\n",
    "        prediction = outputs.cpu().argmax(dim=1)\n",
    "        print(\"    \")\n",
    "        print(\"********predict results***********\")\n",
    "        print(prediction.item())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | conv1 | GraphConv        | 64     | train\n",
      "1 | conv2 | GraphConv        | 34     | train\n",
      "2 | loss  | CrossEntropyLoss | 0      | train\n",
      "---------------------------------------------------\n",
      "98        Trainable params\n",
      "0         Non-trainable params\n",
      "98        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 81.76it/s]Validation epoch ended.\n",
      "Mean validation loss: 0.7349\n",
      "Mean validation accuracy: 0.2000\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n",
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 178/178 [00:02<00:00, 74.00it/s, v_num=79]Validation epoch ended.\n",
      "Mean validation loss: 0.3357\n",
      "Mean validation accuracy: 1.0000\n",
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 79.95it/s, v_num=79, val_loss=0.336]Validation epoch ended.\n",
      "Mean validation loss: 0.8713\n",
      "Mean validation accuracy: 0.0000\n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 78.23it/s, v_num=79, val_loss=0.871]Validation epoch ended.\n",
      "Mean validation loss: 0.9731\n",
      "Mean validation accuracy: 0.0000\n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 78.19it/s, v_num=79, val_loss=0.973]Validation epoch ended.\n",
      "Mean validation loss: 0.9927\n",
      "Mean validation accuracy: 0.0000\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 75.25it/s, v_num=79, val_loss=0.993]Validation epoch ended.\n",
      "Mean validation loss: 0.9965\n",
      "Mean validation accuracy: 0.0000\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 67.80it/s, v_num=79, val_loss=0.997]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 67.61it/s, v_num=79, val_loss=0.997]\n",
      "                                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 98.16it/s] Test epoch ended.\n",
      "Mean test loss: 0.9965\n",
      "Mean test accuracy: 0.0000\n",
      "Testing DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 96.13it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.0\n",
      "        test_loss           0.9964700937271118\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 103.51it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 103.37it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 104.81it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 115.86it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 116.93it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 117.33it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 124.38it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 124.80it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 123.86it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 127.00it/s]    \n",
      "********predict results***********\n",
      "0\n",
      "Predicting DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 127.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]]),\n",
       " tensor([[0.6308, 0.3692]])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from torch.utils.data.sampler import SubsetRandomSampler\n",
    "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=True)\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)\n",
    "num_validation = int(num_examples * 0.9)\n",
    "\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_validation))\n",
    "validation_sampler = SubsetRandomSampler(torch.arange(num_validation, num_examples))\n",
    "\n",
    "train_loader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "test_loader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "validation_loader = GraphDataLoader(\n",
    "    dataset, sampler=validation_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "predict_loader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=1, drop_last=False\n",
    ")'''\n",
    "\n",
    "model = GNNModel()\n",
    "\n",
    "# 创建 Trainer 并在 GPU 上训练\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator='gpu', devices=[0])\n",
    "trainer.fit(model)\n",
    "\n",
    "# 在测试集上测试模型\n",
    "trainer.test(model)\n",
    "\n",
    "# 使用模型进行预测\n",
    "trainer.predict(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
