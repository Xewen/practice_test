{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "\n",
    "import os\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(pl.LightningModule):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, \"h\")\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = model(x , x.ndata[\"attr\"].float())\n",
    "        loss = self.loss(logits, y)\n",
    "        acc = accuracy(logits.softmax(dim=-1), y, task='multiclass', num_classes=2)\n",
    "        pbar = {'train_acc': acc}\n",
    "        return {'loss': loss, 'progress_bar': pbar}\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        results = self.training_step(batch, batch_idx)\n",
    "        results['progress_bar']['test_acc'] = results['progress_bar']['train_acc']\n",
    "        self.log('test_loss', results['loss'], prog_bar=True)\n",
    "        self.log('test_acc', results['progress_bar']['test_acc'])\n",
    "        return results\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        avg_test_loss = self.trainer.callback_metrics['test_loss'].item()\n",
    "        avg_test_acc = self.trainer.callback_metrics['test_acc'].item()\n",
    "        print(\"Test epoch ended.\")\n",
    "        print(f\"Mean test loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Mean test accuracy: {avg_test_acc:.4f}\")\n",
    "\n",
    "        #使用train_step进行验证\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        results = self.training_step(batch, batch_idx)\n",
    "        self.log('val_loss',results['loss'], prog_bar=True)\n",
    "        self.log('val_acc',results['progress_bar']['train_acc'])\n",
    "        return results\n",
    "    \n",
    "    #在每次循环结束后计算其损失以及准确率\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = self.trainer.callback_metrics['val_loss'].item()\n",
    "        avg_val_acc = self.trainer.callback_metrics['val_acc'].item()\n",
    "        print(\"Validation epoch ended.\")\n",
    "        \n",
    "        print(f\"Mean validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        print(f\"Mean validation accuracy: {avg_val_acc:.4f}\")\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        logits = model(x,x.ndata[\"attr\"].float())\n",
    "        preds = logits.softmax(dim=-1)\n",
    "        return preds\n",
    "\n",
    "    def on_predict_batch_end(self, outputs, batch, batch_idx):\n",
    "        prediction = outputs.cpu().argmax(dim=1)\n",
    "        print(\"********predict results***********\")\n",
    "        print(prediction.item())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | conv1 | GraphConv        | 64     | train\n",
      "1 | conv2 | GraphConv        | 34     | train\n",
      "2 | loss  | CrossEntropyLoss | 0      | train\n",
      "---------------------------------------------------\n",
      "98        Trainable params\n",
      "0         Non-trainable params\n",
      "98        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 75.15it/s]Validation epoch ended.\n",
      "Mean validation loss: 0.7019\n",
      "Mean validation accuracy: 0.4000\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n",
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 178/178 [00:02<00:00, 77.53it/s, v_num=57]Validation epoch ended.\n",
      "Mean validation loss: 1.2200\n",
      "Mean validation accuracy: 0.0000\n",
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 78.97it/s, v_num=57, val_loss=1.220]Validation epoch ended.\n",
      "Mean validation loss: 1.0433\n",
      "Mean validation accuracy: 0.1607\n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 78.86it/s, v_num=57, val_loss=1.040]Validation epoch ended.\n",
      "Mean validation loss: 1.2952\n",
      "Mean validation accuracy: 0.0446\n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 79.08it/s, v_num=57, val_loss=1.300]Validation epoch ended.\n",
      "Mean validation loss: 1.2869\n",
      "Mean validation accuracy: 0.0893\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 78.11it/s, v_num=57, val_loss=1.290]Validation epoch ended.\n",
      "Mean validation loss: 1.6113\n",
      "Mean validation accuracy: 0.0000\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 70.31it/s, v_num=57, val_loss=1.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 70.22it/s, v_num=57, val_loss=1.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 106.84it/s]Test epoch ended.\n",
      "Mean test loss: 1.6358\n",
      "Mean test accuracy: 0.0000\n",
      "Testing DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 105.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\learningsoft\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.0\n",
      "        test_loss            1.635769248008728\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Predicting DataLoader 0:   1%|          | 1/111 [00:00<00:01, 99.86it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   2%|▏         | 2/111 [00:00<00:01, 101.46it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   3%|▎         | 3/111 [00:00<00:01, 105.08it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   4%|▎         | 4/111 [00:00<00:00, 107.24it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   5%|▍         | 5/111 [00:00<00:00, 114.63it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   5%|▌         | 6/111 [00:00<00:00, 120.97it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   6%|▋         | 7/111 [00:00<00:00, 124.46it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   7%|▋         | 8/111 [00:00<00:00, 119.67it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   8%|▊         | 9/111 [00:00<00:00, 122.00it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:   9%|▉         | 10/111 [00:00<00:00, 122.36it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  10%|▉         | 11/111 [00:00<00:00, 122.81it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  11%|█         | 12/111 [00:00<00:00, 123.89it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  12%|█▏        | 13/111 [00:00<00:00, 125.17it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  13%|█▎        | 14/111 [00:00<00:00, 125.13it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  14%|█▎        | 15/111 [00:00<00:00, 126.02it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  14%|█▍        | 16/111 [00:00<00:00, 125.81it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  15%|█▌        | 17/111 [00:00<00:00, 127.64it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  16%|█▌        | 18/111 [00:00<00:00, 126.91it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  17%|█▋        | 19/111 [00:00<00:00, 127.84it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  18%|█▊        | 20/111 [00:00<00:00, 129.28it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  19%|█▉        | 21/111 [00:00<00:00, 131.47it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  20%|█▉        | 22/111 [00:00<00:00, 129.54it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  21%|██        | 23/111 [00:00<00:00, 129.39it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  22%|██▏       | 24/111 [00:00<00:00, 128.84it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  23%|██▎       | 25/111 [00:00<00:00, 128.85it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  23%|██▎       | 26/111 [00:00<00:00, 128.14it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  24%|██▍       | 27/111 [00:00<00:00, 124.75it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  25%|██▌       | 28/111 [00:00<00:00, 124.31it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  26%|██▌       | 29/111 [00:00<00:00, 125.08it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  27%|██▋       | 30/111 [00:00<00:00, 125.67it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  28%|██▊       | 31/111 [00:00<00:00, 125.70it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  29%|██▉       | 32/111 [00:00<00:00, 125.17it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  30%|██▉       | 33/111 [00:00<00:00, 125.65it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  31%|███       | 34/111 [00:00<00:00, 126.01it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  32%|███▏      | 35/111 [00:00<00:00, 126.38it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  32%|███▏      | 36/111 [00:00<00:00, 126.27it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  33%|███▎      | 37/111 [00:00<00:00, 127.24it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  34%|███▍      | 38/111 [00:00<00:00, 127.56it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  35%|███▌      | 39/111 [00:00<00:00, 127.82it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  36%|███▌      | 40/111 [00:00<00:00, 129.41it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  37%|███▋      | 41/111 [00:00<00:00, 128.84it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  38%|███▊      | 42/111 [00:00<00:00, 129.00it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  39%|███▊      | 43/111 [00:00<00:00, 129.02it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  40%|███▉      | 44/111 [00:00<00:00, 129.24it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  41%|████      | 45/111 [00:00<00:00, 129.07it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  41%|████▏     | 46/111 [00:00<00:00, 129.63it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  42%|████▏     | 47/111 [00:00<00:00, 130.00it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  43%|████▎     | 48/111 [00:00<00:00, 130.95it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  44%|████▍     | 49/111 [00:00<00:00, 129.88it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  45%|████▌     | 50/111 [00:00<00:00, 129.73it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  46%|████▌     | 51/111 [00:00<00:00, 130.20it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  47%|████▋     | 52/111 [00:00<00:00, 130.06it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  48%|████▊     | 53/111 [00:00<00:00, 130.46it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  49%|████▊     | 54/111 [00:00<00:00, 129.48it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  50%|████▉     | 55/111 [00:00<00:00, 129.39it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  50%|█████     | 56/111 [00:00<00:00, 130.15it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  51%|█████▏    | 57/111 [00:00<00:00, 129.73it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  52%|█████▏    | 58/111 [00:00<00:00, 130.60it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  53%|█████▎    | 59/111 [00:00<00:00, 130.04it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  54%|█████▍    | 60/111 [00:00<00:00, 129.96it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  55%|█████▍    | 61/111 [00:00<00:00, 130.19it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  56%|█████▌    | 62/111 [00:00<00:00, 130.36it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  57%|█████▋    | 63/111 [00:00<00:00, 130.76it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  58%|█████▊    | 64/111 [00:00<00:00, 131.62it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  59%|█████▊    | 65/111 [00:00<00:00, 131.55it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  59%|█████▉    | 66/111 [00:00<00:00, 131.22it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  60%|██████    | 67/111 [00:00<00:00, 131.05it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  61%|██████▏   | 68/111 [00:00<00:00, 129.99it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  62%|██████▏   | 69/111 [00:00<00:00, 128.59it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  63%|██████▎   | 70/111 [00:00<00:00, 128.17it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  64%|██████▍   | 71/111 [00:00<00:00, 127.35it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  65%|██████▍   | 72/111 [00:00<00:00, 127.10it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  66%|██████▌   | 73/111 [00:00<00:00, 127.46it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  67%|██████▋   | 74/111 [00:00<00:00, 127.96it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  68%|██████▊   | 75/111 [00:00<00:00, 128.02it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  68%|██████▊   | 76/111 [00:00<00:00, 128.60it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  69%|██████▉   | 77/111 [00:00<00:00, 128.34it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  70%|███████   | 78/111 [00:00<00:00, 128.60it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  71%|███████   | 79/111 [00:00<00:00, 128.68it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  72%|███████▏  | 80/111 [00:00<00:00, 128.53it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  73%|███████▎  | 81/111 [00:00<00:00, 128.95it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  74%|███████▍  | 82/111 [00:00<00:00, 129.25it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  75%|███████▍  | 83/111 [00:00<00:00, 129.48it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  76%|███████▌  | 84/111 [00:00<00:00, 129.60it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  77%|███████▋  | 85/111 [00:00<00:00, 129.38it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  77%|███████▋  | 86/111 [00:00<00:00, 129.55it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  78%|███████▊  | 87/111 [00:00<00:00, 129.92it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  79%|███████▉  | 88/111 [00:00<00:00, 130.31it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  80%|████████  | 89/111 [00:00<00:00, 130.52it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  81%|████████  | 90/111 [00:00<00:00, 130.29it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  82%|████████▏ | 91/111 [00:00<00:00, 130.41it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  83%|████████▎ | 92/111 [00:00<00:00, 130.65it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  84%|████████▍ | 93/111 [00:00<00:00, 130.75it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  85%|████████▍ | 94/111 [00:00<00:00, 130.71it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  86%|████████▌ | 95/111 [00:00<00:00, 131.15it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  86%|████████▋ | 96/111 [00:00<00:00, 131.17it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  87%|████████▋ | 97/111 [00:00<00:00, 131.15it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  88%|████████▊ | 98/111 [00:00<00:00, 131.48it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  89%|████████▉ | 99/111 [00:00<00:00, 131.23it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  90%|█████████ | 100/111 [00:00<00:00, 130.80it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  91%|█████████ | 101/111 [00:00<00:00, 130.86it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  92%|█████████▏| 102/111 [00:00<00:00, 131.21it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  93%|█████████▎| 103/111 [00:00<00:00, 131.30it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  94%|█████████▎| 104/111 [00:00<00:00, 131.51it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  95%|█████████▍| 105/111 [00:00<00:00, 131.51it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  95%|█████████▌| 106/111 [00:00<00:00, 132.00it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  96%|█████████▋| 107/111 [00:00<00:00, 131.77it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  97%|█████████▋| 108/111 [00:00<00:00, 131.87it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  98%|█████████▊| 109/111 [00:00<00:00, 131.94it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0:  99%|█████████▉| 110/111 [00:00<00:00, 131.93it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0: 100%|██████████| 111/111 [00:00<00:00, 131.95it/s]********predict results***********\n",
      "tensor([0])\n",
      "Predicting DataLoader 0: 100%|██████████| 111/111 [00:00<00:00, 131.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[0.9159, 0.0841]]),\n",
       " tensor([[0.7961, 0.2039]]),\n",
       " tensor([[0.8400, 0.1600]]),\n",
       " tensor([[0.7167, 0.2833]]),\n",
       " tensor([[0.9007, 0.0993]]),\n",
       " tensor([[0.5866, 0.4134]]),\n",
       " tensor([[0.7491, 0.2509]]),\n",
       " tensor([[0.5860, 0.4140]]),\n",
       " tensor([[0.5232, 0.4768]]),\n",
       " tensor([[0.8872, 0.1128]]),\n",
       " tensor([[0.6253, 0.3747]]),\n",
       " tensor([[0.9012, 0.0988]]),\n",
       " tensor([[0.8072, 0.1928]]),\n",
       " tensor([[0.5236, 0.4764]]),\n",
       " tensor([[0.8626, 0.1374]]),\n",
       " tensor([[0.8828, 0.1172]]),\n",
       " tensor([[0.5276, 0.4724]]),\n",
       " tensor([[0.8720, 0.1280]]),\n",
       " tensor([[0.8917, 0.1083]]),\n",
       " tensor([[0.8185, 0.1815]]),\n",
       " tensor([[0.5860, 0.4140]]),\n",
       " tensor([[0.5226, 0.4774]]),\n",
       " tensor([[0.9140, 0.0860]]),\n",
       " tensor([[0.8385, 0.1615]]),\n",
       " tensor([[0.7653, 0.2347]]),\n",
       " tensor([[0.7202, 0.2798]]),\n",
       " tensor([[0.9357, 0.0643]]),\n",
       " tensor([[0.9078, 0.0922]]),\n",
       " tensor([[0.7616, 0.2384]]),\n",
       " tensor([[0.5232, 0.4768]]),\n",
       " tensor([[0.5867, 0.4133]]),\n",
       " tensor([[0.7382, 0.2618]]),\n",
       " tensor([[0.8821, 0.1179]]),\n",
       " tensor([[0.9041, 0.0959]]),\n",
       " tensor([[0.8971, 0.1029]]),\n",
       " tensor([[0.9097, 0.0903]]),\n",
       " tensor([[0.8409, 0.1591]]),\n",
       " tensor([[0.8334, 0.1666]]),\n",
       " tensor([[0.5897, 0.4103]]),\n",
       " tensor([[0.5866, 0.4134]]),\n",
       " tensor([[0.7008, 0.2992]]),\n",
       " tensor([[0.6465, 0.3535]]),\n",
       " tensor([[0.7275, 0.2725]]),\n",
       " tensor([[0.5862, 0.4138]]),\n",
       " tensor([[0.8270, 0.1730]]),\n",
       " tensor([[0.8535, 0.1465]]),\n",
       " tensor([[0.8564, 0.1436]]),\n",
       " tensor([[0.6503, 0.3497]]),\n",
       " tensor([[0.8946, 0.1054]]),\n",
       " tensor([[0.9221, 0.0779]]),\n",
       " tensor([[0.5862, 0.4138]]),\n",
       " tensor([[0.5867, 0.4133]]),\n",
       " tensor([[0.5867, 0.4133]]),\n",
       " tensor([[0.8404, 0.1596]]),\n",
       " tensor([[0.9074, 0.0926]]),\n",
       " tensor([[0.8979, 0.1021]]),\n",
       " tensor([[0.9171, 0.0829]]),\n",
       " tensor([[0.8316, 0.1684]]),\n",
       " tensor([[0.8658, 0.1342]]),\n",
       " tensor([[0.8396, 0.1604]]),\n",
       " tensor([[0.8687, 0.1313]]),\n",
       " tensor([[0.8882, 0.1118]]),\n",
       " tensor([[0.5235, 0.4765]]),\n",
       " tensor([[0.5689, 0.4311]]),\n",
       " tensor([[0.5860, 0.4140]]),\n",
       " tensor([[0.5867, 0.4133]]),\n",
       " tensor([[0.5863, 0.4137]]),\n",
       " tensor([[0.7462, 0.2538]]),\n",
       " tensor([[0.9149, 0.0851]]),\n",
       " tensor([[0.7700, 0.2300]]),\n",
       " tensor([[0.8317, 0.1683]]),\n",
       " tensor([[0.9269, 0.0731]]),\n",
       " tensor([[0.8757, 0.1243]]),\n",
       " tensor([[0.8272, 0.1728]]),\n",
       " tensor([[0.8895, 0.1105]]),\n",
       " tensor([[0.9174, 0.0826]]),\n",
       " tensor([[0.5877, 0.4123]]),\n",
       " tensor([[0.5862, 0.4138]]),\n",
       " tensor([[0.8050, 0.1950]]),\n",
       " tensor([[0.5245, 0.4755]]),\n",
       " tensor([[0.8337, 0.1663]]),\n",
       " tensor([[0.9128, 0.0872]]),\n",
       " tensor([[0.8240, 0.1760]]),\n",
       " tensor([[0.8676, 0.1324]]),\n",
       " tensor([[0.8840, 0.1160]]),\n",
       " tensor([[0.7426, 0.2574]]),\n",
       " tensor([[0.7510, 0.2490]]),\n",
       " tensor([[0.7026, 0.2974]]),\n",
       " tensor([[0.8492, 0.1508]]),\n",
       " tensor([[0.8654, 0.1346]]),\n",
       " tensor([[0.9030, 0.0970]]),\n",
       " tensor([[0.7848, 0.2152]]),\n",
       " tensor([[0.5862, 0.4138]]),\n",
       " tensor([[0.8958, 0.1042]]),\n",
       " tensor([[0.8557, 0.1443]]),\n",
       " tensor([[0.5869, 0.4131]]),\n",
       " tensor([[0.7888, 0.2112]]),\n",
       " tensor([[0.5233, 0.4767]]),\n",
       " tensor([[0.7262, 0.2738]]),\n",
       " tensor([[0.8818, 0.1182]]),\n",
       " tensor([[0.9104, 0.0896]]),\n",
       " tensor([[0.8810, 0.1190]]),\n",
       " tensor([[0.8254, 0.1746]]),\n",
       " tensor([[0.5864, 0.4136]]),\n",
       " tensor([[0.5867, 0.4133]]),\n",
       " tensor([[0.8843, 0.1157]]),\n",
       " tensor([[0.8729, 0.1271]]),\n",
       " tensor([[0.7848, 0.2152]]),\n",
       " tensor([[0.5775, 0.4225]]),\n",
       " tensor([[0.8799, 0.1201]]),\n",
       " tensor([[0.9114, 0.0886]])]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=True)\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)\n",
    "num_validation = int(num_examples * 0.9)\n",
    "print(num_examples)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_validation))\n",
    "validation_sampler = SubsetRandomSampler(torch.arange(num_validation, num_examples))\n",
    "\n",
    "train_loader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "test_loader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "validation_loader = GraphDataLoader(\n",
    "    dataset, sampler=validation_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "predict_loader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=1, drop_last=False\n",
    ")\n",
    "\n",
    "model = GNNModel(dataset.dim_nfeats, 16, dataset.gclasses)\n",
    "\n",
    "# 创建 Trainer 并在 GPU 上训练\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator='gpu', devices=[0])\n",
    "trainer.fit(model,train_loader,validation_loader)\n",
    "\n",
    "# 在测试集上测试模型\n",
    "trainer.test(model,test_loader)\n",
    "\n",
    "# 使用模型进行预测\n",
    "trainer.predict(model,predict_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
